if (is.null(url)) return(NULL)
closeAllConnections()  # Cerrar las conexiones abiertas por `read_html`
# Extraer los títulos de las noticias, sus enlaces y fechas
titulo <- url %>% html_nodes(".td-module-title a") %>% html_text()  %>% basic_clean()
link <- url %>% html_nodes(".td-module-title a") %>% html_attr("href")  %>% basic_clean()
fecha_publicacion_str <- url %>% html_nodes(".td-module-date") %>% html_text() %>% basic_clean()
municipio <- mun_raw[i] # Asignar el municipio actual
oid <- OID # Asignar el OID (ID de la fuente)
# Crear un data frame con la información extraída
Notas <- data.frame(link, estado = ESTADO, municipio, oid, fuente, titulo, fecha_publicacion_str)
# Eliminar duplicados manteniendo la primera ocurrencia
#Notas <- Notas %>% distinct(link, .keep_all = TRUE)
N <-NULL # Inicializar una variable para almacenar los detalles de cada noticia
# Iterar sobre cada enlace de noticia para obtener más detalles
N <- do.call(rbind, mclapply(Notas$link, function(nota_link) {
tryCatch({
url <- tryCatch(read_html(nota_link), error = function(e) NULL) # Leer el HTML de la página de la noticia
if (is.null(url)) return(NULL)
closeAllConnections() # Cerrar las conexiones abiertas por `read_html`
# basic_clean() es una función definida en functions_all.R que nos ayuda a limpiar caracteres no deseados
# Extraer la información
resumen <- url %>% html_nodes(".td-excerpt") %>% html_text() %>% basic_clean()
# En muchos casos van a observar que no hay un resumen de la noticia, por lo que tienen que agregar:
resumen <- if (length(resumen) == 0) NA else paste(resumen, collapse = " ") %>% basic_clean() #creo q acá hay en todos pero lo dejo por las dudas
seccion <- url %>% html_nodes(".td-post-category") %>% html_text() %>% basic_clean()
# En muchos casos van a observar que no esta la sección de la noticia, por lo que tienen que agregar:
seccion <- if (length(seccion) == 0) NA else paste(seccion, collapse = " ") %>% basic_clean()
nota <- url %>%
html_nodes(".td-post-content p") %>% # Cambia a la clase correcta si el contenido está en otro lugar
html_text() %>%
paste(collapse = " ") %>% # Unir párrafos en un solo texto
basic_clean()
# Crear un data frame con los detalles de la noticia
data.frame(nota_link, nota, seccion, resumen)
}, error = function(e) {
cat("ERROR en nota_link:", nota_link, ":", conditionMessage(e), "\n")
NULL
})
}, mc.preschedule=TRUE))
# Agrega variables al data.frame Notas
Notas <- Notas %>%
left_join(N, by = c("link" = "nota_link"))
# Formatea la fecha de publicación
# string_fecha_a_fecha() es una función definida en functions_all.R que convierte la fecha al formato deseado
Notas$fecha_publicacion <- string_fecha_a_fecha(Notas$fecha_publicacion_str)
# Formatear las columnas del data frame
colnames(Notas) <- tolower(colnames(Notas)) # Convertir los nombres de las columnas a minúsculas
Notas <- Notas[, c(COLS_ORDENADAS)]  # Reordenar las columnas según una lista predefinida
return(Notas)
}, error = function(e) {
cat("ERROR :", conditionMessage(e), "\n")
NULL
})
}, mc.preschedule=TRUE) # Cierre de mclapply para last_page
# Almacena resultados de cada municipio
Notas_municipio <- do.call(rbind, Notas_municipio)
# Guardar en la base de datos
# descomentar cuando ya hayan probado que el codigo funciona correctamente para subir la info a la base de datos)
#dbWriteTable(con, TABLA, Notas_municipio, append = TRUE)
# Imprimir el progreso de la recolección de noticias
print(paste0("Municipio procesado: ", mun_raw[i]))
}
}
# Cierra conexión a la base de datos
# descomentar cuando ya hayan probado que el codigo funciona correctamente)
# dbDisconnect(con)
})
# Limpiar el entorno de trabajo (elimina todas las variables del entorno)
rm(list=ls())
# Cargar las librerías necesarias de manera silenciosa (sin mostrar mensajes)
library(rvest)         # Para hacer web scraping
library(xml2)          # Manipulación de archivos HTML/XML
library(dplyr)         # Manipulación de datos
library(DBI)           # Conexión con bases de datos
library(taRifx)        # Funciones adicionales de manipulación de texto
library(parallel)      # Loop
# Se define el usurario
user <- "/Users/ninadicostanzopereira"
# Se define el directorio donde están los archivos
DIR <- paste0(user, "/Nextcloud/San Andres/R")
# Definir identificadores para la fuente y la tabla en la base de datos
OID <- "91"  # ID de la fuente => nosotros le vamos a compartir las fuentes con sus IDs
TABLA <- "historicas_2024"  # Nombre de la tabla donde se almacenarán las noticias
# Cargar funciones adicionales desde un archivo de código externo
# Ejecutar primero en la terminal: cloudflared access tcp --hostname sqldb.odp-srv.org --url 127.0.0.1:9210
source(paste0(DIR, "/functions_all.R"))  # Cargar funciones personalizadas
# Imprimir un mensaje para indicar el inicio
print(paste0("***************", OID, "***************\n"))
# Ejecutar el código dentro de un bloque para medir el tiempo de ejecución
system.time({
# Establecer la conexión con la base de datos => descomentar cuando ya hayan probado que el codigo funciona correctamente para subir la info a la base de datos)
#con <- DBI::dbConnect(RPostgres::Postgres(), dbname = "Noticias", host = "127.0.0.1", port = 9210, user = "san_andres", password = "odpserver")
#dbListTables(con)
# Obtener datos generales relacionados con la fuente desde la base de datos
data <- obtiene_data_gral_fuente(OID)  # Función para obtener información de la fuente (definida en functions_all.R)
ESTADO <- data$edo  # Extraer el nombre del estado
BASE_URL <- data$base_url  # Extraer la URL base del sitio web de la fuente
fuente <- data$fuente  # Extraer el nombre de la fuente de noticias
# Obtener la lista de municipios relacionados con el estado
mun <- municipios_del_estado(ESTADO)  # Función para obtener los municipios del estado (definida en functions_all.R)
mun <- head(mun, 3)
mun_raw <- a_minusculas_sin_acentos(mun, "+")  # Convertir a minúsculas y reemplazar acentos (definida en functions_all.R)
n_mun <- length(mun)  # Número de municipios a procesar
# Iterar sobre cada municipio para realizar la búsqueda de noticias
for (i in seq_along(mun_raw)) {
# Construir la URL para la búsqueda de noticias por municipio
url <- paste0(BASE_URL, "/?s=", mun_raw[i]) # Construir la URL => esto va a cambiar según la fuente
url <- paste0(BASE_URL, "/?s=", mun_raw[1]) #TEST
url <- tryCatch(read_html(url), error = function(e) NULL) # Leer el HTML de la página web
if (is.null(url)) next
closeAllConnections() # Cerrar conexiones abiertas por `read_html`
# De aquí en adelante todos los que esta dentro de html_nodes debe ser reemplazado según
# el contenido del html de cada página, estos son valores inventados como modelo
# Obtener el número total de páginas de resultados de búsqueda => esto va a cambiar según la fuente
last_page <- url %>%
html_nodes("a.last") %>%
html_attr("href") %>%
stringr::str_extract("\\d+(?=/\\?s=)") %>%
as.numeric()
last_page <- 3
print(paste("(", i, "/", n_mun, ")", mun_raw[i], ":", last_page)) # Imprimir el municipio y el número de la última página
# Si hay páginas de resultados, proceder con el scraping de esas páginas
if (!is.na(last_page) && last_page > 0) {
# Iterar sobre cada página de resultados de la búsqueda (en paralelo)
Notas_municipio <- mclapply(1:last_page, function(page) {
tryCatch({
# Construir la URL de la página actual de búsqueda
url <- paste0(BASE_URL, "page/", page, "?s=",  mun_raw[i])
url <- tryCatch(read_html(url), error = function(e) NULL) # Leer el HTML de la página de resultados
if (is.null(url)) return(NULL)
closeAllConnections()  # Cerrar las conexiones abiertas por `read_html`
# Extraer los títulos de las noticias, sus enlaces y fechas
titulo <- url %>% html_nodes(".td-module-title a") %>% html_text()  %>% basic_clean()
link <- url %>% html_nodes(".td-module-title a") %>% html_attr("href")  %>% basic_clean()
fecha_publicacion_str <- url %>% html_nodes(".td-module-date") %>% html_text() %>% basic_clean()
municipio <- mun_raw[i] # Asignar el municipio actual
oid <- OID # Asignar el OID (ID de la fuente)
# Crear un data frame con la información extraída
Notas <- data.frame(link, estado = ESTADO, municipio, oid, fuente, titulo, fecha_publicacion_str)
# Eliminar duplicados manteniendo la primera ocurrencia
#Notas <- Notas %>% distinct(link, .keep_all = TRUE)
N <-NULL # Inicializar una variable para almacenar los detalles de cada noticia
# Iterar sobre cada enlace de noticia para obtener más detalles
N <- do.call(rbind, mclapply(Notas$link, function(nota_link) {
tryCatch({
url <- tryCatch(read_html(nota_link), error = function(e) NULL) # Leer el HTML de la página de la noticia
if (is.null(url)) return(NULL)
closeAllConnections() # Cerrar las conexiones abiertas por `read_html`
# basic_clean() es una función definida en functions_all.R que nos ayuda a limpiar caracteres no deseados
# Extraer la información
resumen <- url %>% html_nodes(".td-excerpt") %>% html_text() %>% basic_clean()
# En muchos casos van a observar que no hay un resumen de la noticia, por lo que tienen que agregar:
resumen <- if (length(resumen) == 0) NA else paste(resumen, collapse = " ") %>% basic_clean() #creo q acá hay en todos pero lo dejo por las dudas
seccion <- url %>% html_nodes(".td-post-category") %>% html_text() %>% basic_clean()
# En muchos casos van a observar que no esta la sección de la noticia, por lo que tienen que agregar:
seccion <- if (length(seccion) == 0) NA else paste(seccion, collapse = " ") %>% basic_clean()
nota <- url %>%
html_nodes(".td-post-content p") %>% # Cambia a la clase correcta si el contenido está en otro lugar
html_text() %>%
paste(collapse = " ") %>% # Unir párrafos en un solo texto
basic_clean()
# Crear un data frame con los detalles de la noticia
data.frame(nota_link, nota, seccion, resumen)
}, error = function(e) {
cat("ERROR en nota_link:", nota_link, ":", conditionMessage(e), "\n")
NULL
})
}, mc.preschedule=TRUE))
# Agrega variables al data.frame Notas
Notas <- Notas %>%
left_join(N, by = c("link" = "nota_link"))
# Formatea la fecha de publicación
# string_fecha_a_fecha() es una función definida en functions_all.R que convierte la fecha al formato deseado
Notas$fecha_publicacion <- string_fecha_a_fecha(Notas$fecha_publicacion_str)
# Formatear las columnas del data frame
colnames(Notas) <- tolower(colnames(Notas)) # Convertir los nombres de las columnas a minúsculas
Notas <- Notas[, c(COLS_ORDENADAS)]  # Reordenar las columnas según una lista predefinida
return(Notas)
}, error = function(e) {
cat("ERROR :", conditionMessage(e), "\n")
NULL
})
}, mc.preschedule=TRUE) # Cierre de mclapply para last_page
# Almacena resultados de cada municipio
Notas_municipio <- do.call(rbind, Notas_municipio)
# Guardar en la base de datos
# descomentar cuando ya hayan probado que el codigo funciona correctamente para subir la info a la base de datos)
#dbWriteTable(con, TABLA, Notas_municipio, append = TRUE)
# Imprimir el progreso de la recolección de noticias
print(paste0("Municipio procesado: ", mun_raw[i]))
}
}
# Cierra conexión a la base de datos
# descomentar cuando ya hayan probado que el codigo funciona correctamente)
# dbDisconnect(con)
})
rm(list=ls())
#librerías necesarias
library(readr)
library(dplyr)
library(stargazer)
library(fixest)
library(plm)
setwd("/Users/ninadicostanzopereira/Desktop/ECONOMETR-A/tp3/")
install.packages('haven')
library(haven)
df <- read_dta('QOB.dta')
library(dplyr)
library(summarytools)
install.packages('sumarytools')
library(dplyr)
library(summarytools)
install.packages('summarytools')
library(dplyr)
library(summarytools)
library(summarytools)
datos %>%
select(age, ageq, ageqsq, educ, lwage, married, race, smsa) %>%
descr(stats = "common", transpose = TRUE)
x <- "educ"
group_by(qob) %>%
mutate(
# Media de x dentro de cada grupo (qob)
!!paste0(x, "_mean_qob") := mean(!!sym(x), na.rm = TRUE),
) %>%
ungroup()
View(df)
df[qob]
df['qob']
group_by(df['qob']) %>%
mutate(
# Media de x dentro de cada grupo (qob)
!!paste0(x, "_mean_qob") := mean(!!sym(x), na.rm = TRUE),
) %>%
ungroup()
x <- "educ"
group_by(df['qob']) %>%
mutate(
# Media de x dentro de cada grupo (qob)
!!paste0(x, "_mean_qob") := mean(!!sym(x), na.rm = TRUE),
) %>%
ungroup()
x <- df['educ']
group_by(df['qob']) %>%
mutate(
!!paste0(x, "_mean_qob") := mean(!!sym(x), na.rm = TRUE),
) %>%
ungroup()
head(df)
x <- df$'educ'
library(rlang)
x <- "educ"
df <- df %>%
group_by(qob) %>%
mutate(
!!paste0(x, "_mean_qob") := mean(.data[[x]], na.rm = TRUE),
!!paste0(x, "_centered") := .data[[x]] - mean(.data[[x]], na.rm = TRUE)
) %>%
ungroup()
View(df)
#install.packages('haven')
install.packages('summarytools')
#limpio entorno
rm(list=ls())
#librerías necesarias
library(haven)
library(readr)
library(dplyr)
library(stargazer)
library(fixest)
library(plm)
library(summarytools)
#install.packages('haven')
#install.packages('summarytools')
#limpio entorno
rm(list=ls())
#librerías necesarias
library(haven)
library(readr)
library(dplyr)
library(stargazer)
library(fixest)
library(plm)
library(summarytools)
library(rlang)
setwd("/Users/ninadicostanzopereira/Desktop/ECONOMETR-A/tp3/")
#importo la base d datos
df <- read_dta('QOB.dta')
x <- 'educ'
df <- df %>%
group_by(qob) %>%
mutate(
!!paste0(x, "_mean_qob") := mean(.data[[x]], na.rm = TRUE),
) %>%
ungroup()
install.packages("ggplot2")
library(ggplot2)
ggplot(educ_promedio_qob, aes(x = factor(qob), y = promedio_educ)) +
geom_col(fill = "steelblue") +
labs(
title = "Promedio de Años de Escolaridad por Trimestre de Nacimiento",
x = "Trimestre de Nacimiento (qob)",
y = "Años de escolaridad (promedio)"
) +
theme_minimal() +
theme(
plot.title = element_text(size = 14, face = "bold"),
axis.title = element_text(size = 12)
)
educ_promedio_qob <- df %>%
group_by(qob) %>%
summarise(
promedio_educ = mean(educ, na.rm = TRUE),
n = n()
)
ggplot(educ_promedio_qob, aes(x = factor(qob), y = promedio_educ)) +
geom_col(fill = "steelblue") +
labs(
title = "Promedio de Años de Escolaridad por Trimestre de Nacimiento",
x = "Trimestre de Nacimiento (qob)",
y = "Años de escolaridad (promedio)"
) +
theme_minimal() +
theme(
plot.title = element_text(size = 14, face = "bold"),
axis.title = element_text(size = 12)
)
View(educ_promedio_qob)
educ_promedio_qob <- df %>%
+     group_by(qob) %>%
+     summarise(
+         promedio_educ = mean(educ, na.rm = TRUE),
educ_promedio_qob <- df %>%
group_by(qob) %>%
summarise(
promedio_educ = mean(educ, na.rm = TRUE),
n = n()
)
ggplot(educ_promedio_qob, aes(x = factor(qob), y = promedio_educ)) +
geom_col(fill = "steelblue") +
labs(
title = "Promedio de Años de Escolaridad por Trimestre de Nacimiento",
x = "Trimestre de Nacimiento (qob)",
y = "Años de escolaridad (promedio)"
) +
theme_minimal() +
theme(
plot.title = element_text(size = 14, face = "bold"),
axis.title = element_text(size = 12)
)
ggplot(educ_promedio_qob, aes(x = factor(qob), y = promedio_educ)) +
geom_col(fill = "steelblue") +
geom_text(aes(label = round(promedio_educ, 2)), vjust = -0.5) +
labs(
title = "Promedio de Años de Escolaridad por Trimestre de Nacimiento",
x = "Trimestre de Nacimiento (qob)",
y = "Años de escolaridad (promedio)"
) +
coord_cartesian(ylim = c(11.5, 13.5)) +  # ajustá el rango según tus datos
theme_minimal() +
theme(
plot.title = element_text(size = 14, face = "bold"),
axis.title = element_text(size = 12)
)
summarise(age)
summarise(df$age)
summary(age)
summary(df$age)
summary(select(data, educ, lwage, age, ageq, ageqsq, race, married, smsa, qob))
summary(select(df, educ, lwage, age, ageq, ageqsq, race, married, smsa, qob))
#estad descriptiva
summary(select(df, educ, lwage, age, ageq, ageqsq, race, married, smsa, qob))
vars <- select(data, educ, lwage, age, ageq, ageqsq, race, married, smsa, qob)
vars <- select(df, educ, lwage, age, ageq, ageqsq, race, married, smsa, qob)
# Exportar tabla en formato LaTeX
stargazer(vars, type = "latex", title = "Estadísticos descriptivos",
summary.stat = c("mean", "sd", "min", "max"),
out = "tabla_descriptivos.tex")
vars <- select(df, educ, lwage, age, ageq, ageqsq, race, married, smsa, qob)
summary(select(df, educ, lwage, age, ageq, ageqsq, race, married, smsa, qob))
varianza_muestral <- var(select(df, educ))
View(varianza_muestral)
data_filtered <- data %>%
filter(yob >= 1930, yob <= 1939)
data_filtered <- df %>%
filter(yob >= 1930, yob <= 1939)
View(data_filtered)
View(df)
data_filtered <- df %>%
filter(yob >= 30, yob <= 39)
# Filtrar hombres nacidos entre 1930 y 1939
data_filtrado <- df %>%
filter(yob >= 30, yob <= 39)
Modelo <- lm(lwage ~ educ + ageq + ageqsq + race + married + smsa, data = data_filtrado)
# Ver resultados
summary(Modelo)
stargazer(Modelo, type = "latex",
title = "Regresión por MCO: Retornos a la educación",
dep.var.labels = "Logaritmo del salario mensual",
covariate.labels = c("Años de educación", "Edad (trimestres)", "Edad al cuadrado",
"Raza (dummy)", "Casado (dummy)", "Ciudad central (dummy)"),
digits = 3,
out = "mco_educacion.tex")
data_filtrado <- data_filtrado %>%
mutate(Z1 = ifelse(qob == 1, 1, 0),
Z2 = ifelse(qob == 2, 1, 0),
Z3 = ifelse(qob == 3, 1, 0))
View(data_filtrado)
educ_iv_reg <- lm(educ ~ Z1 + Z2 + Z3, data = data_filtrado)
summary(educ_iv_reg)
anova(educ_iv_reg)
stargazer(educ_iv_reg,
type = "latex",
title = "Regresión de educación sobre los instrumentos (trimestres de nacimiento)",
dep.var.labels = "Años de educación",
covariate.labels = c("1er Trimestre (Z1)", "2do Trimestre (Z2)", "3er Trimestre (Z3)"),
digits = 3,
out = "educ_sobre_instrumentos.tex")
#install.packages('haven')
#install.packages('summarytools')
#install.packages("ggplot2")
#limpio entorno
rm(list=ls())
#librerías necesarias
library(haven)
library(readr)
library(dplyr)
library(stargazer)
library(fixest)
library(plm)
library(summarytools)
#install.packages('haven')
#install.packages('summarytools')
#install.packages("ggplot2")
#limpio entorno
rm(list=ls())
#install.packages('haven')
#install.packages('summarytools')
#install.packages("ggplot2")
#limpio entorno
rm(list=ls())
#librerías necesarias
library(haven)
library(readr)
library(dplyr)
library(stargazer)
library(fixest)
library(plm)
library(summarytools)
library(rlang)
library(ggplot2)
setwd("/Users/ninadicostanzopereira/Desktop/ECONOMETR-A/tp3/")
#importo la base d datos
df <- read_dta('QOB.dta')
educ_promedio_qob <- df %>%
group_by(qob) %>%
summarise(
promedio_educ = mean(educ, na.rm = TRUE),
n = n()
)
ggplot(educ_promedio_qob, aes(x = factor(qob), y = promedio_educ)) +
geom_col(fill = "steelblue") +
geom_text(aes(label = round(promedio_educ, 2)), vjust = -0.5) +
labs(
title = "Promedio de Años de Escolaridad por Trimestre de Nacimiento",
x = "Trimestre de Nacimiento (qob)",
y = "Años de escolaridad (promedio)"
) +
coord_cartesian(ylim = c(11.5, 13.5)) +  # ajustá el rango según tus datos
theme_minimal() +
theme(
plot.title = element_text(size = 14, face = "bold"),
axis.title = element_text(size = 12)
)
#estad descriptiva
summary(select(df, educ, lwage, age, ageq, ageqsq, race, married, smsa, qob))
# Seleccionar las variables relevantes
vars <- select(df, educ, lwage, age, ageq, ageqsq, race, married, smsa, qob)
# Exportar tabla en formato LaTeX
stargazer(vars, type = "latex", title = "Estadísticos descriptivos",
summary.stat = c("mean", "sd", "min", "max"),
out = "tabla_descriptivos.tex")
# Filtrar hombres nacidos entre 1930 y 1939
data_filtrado <- df %>%
filter(yob >= 30, yob <= 39)
Modelo <- lm(lwage ~ educ + ageq + ageqsq + race + married + smsa, data = data_filtrado)
# Ver resultados
summary(Modelo)
stargazer(Modelo, type = "latex",
title = "Regresión por MCO: Retornos a la educación",
dep.var.labels = "Logaritmo del salario mensual",
covariate.labels = c("Años de educación", "Edad (trimestres)", "Edad al cuadrado",
"Raza (dummy)", "Casado (dummy)", "Ciudad central (dummy)"),
digits = 3,
out = "mco_educacion.tex")
#---------------------------------------d---------------------------------------
data_filtrado <- data_filtrado %>%
mutate(Z1 = ifelse(qob == 1, 1, 0),
Z2 = ifelse(qob == 2, 1, 0),
Z3 = ifelse(qob == 3, 1, 0))
# Regresamos los instrumentos en educación
educ_iv_reg <- lm(educ ~ Z1 + Z2 + Z3, data = data_filtrado)
summary(educ_iv_reg)
# Test F
anova(educ_iv_reg)
stargazer(educ_iv_reg,
type = "latex",
title = "Regresión de educación sobre los instrumentos (trimestres de nacimiento)",
dep.var.labels = "Años de educación",
covariate.labels = c("1er Trimestre (Z1)", "2do Trimestre (Z2)", "3er Trimestre (Z3)"),
digits = 3,
out = "educ_sobre_instrumentos.tex")
